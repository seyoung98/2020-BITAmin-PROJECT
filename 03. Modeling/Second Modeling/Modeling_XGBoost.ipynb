{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18159 entries, 0 to 18158\n",
      "Data columns (total 83 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Name                      18159 non-null  object \n",
      " 1   Age                       18159 non-null  int64  \n",
      " 2   Nationality               18159 non-null  object \n",
      " 3   Overall                   18159 non-null  int64  \n",
      " 4   Potential                 18159 non-null  int64  \n",
      " 5   Club                      17918 non-null  object \n",
      " 6   Value                     18159 non-null  int64  \n",
      " 7   Wage                      18159 non-null  int64  \n",
      " 8   Special                   18159 non-null  int64  \n",
      " 9   Preferred Foot            18159 non-null  object \n",
      " 10  International Reputation  18159 non-null  float64\n",
      " 11  Weak Foot                 18159 non-null  float64\n",
      " 12  Skill Moves               18159 non-null  float64\n",
      " 13  Work Rate                 18159 non-null  object \n",
      " 14  Body Type                 18159 non-null  object \n",
      " 15  Position                  18147 non-null  object \n",
      " 16  Jersey Number             18147 non-null  float64\n",
      " 17  Joined                    16654 non-null  object \n",
      " 18  Contract Valid Until      17918 non-null  float64\n",
      " 19  Height                    18159 non-null  float64\n",
      " 20  Weight                    18159 non-null  float64\n",
      " 21  LS                        16122 non-null  float64\n",
      " 22  ST                        16122 non-null  float64\n",
      " 23  RS                        16122 non-null  float64\n",
      " 24  LW                        16122 non-null  float64\n",
      " 25  LF                        16122 non-null  float64\n",
      " 26  CF                        16122 non-null  float64\n",
      " 27  RF                        16122 non-null  float64\n",
      " 28  RW                        16122 non-null  float64\n",
      " 29  LAM                       16122 non-null  float64\n",
      " 30  CAM                       16122 non-null  float64\n",
      " 31  RAM                       16122 non-null  float64\n",
      " 32  LM                        16122 non-null  float64\n",
      " 33  LCM                       16122 non-null  float64\n",
      " 34  CM                        16122 non-null  float64\n",
      " 35  RCM                       16122 non-null  float64\n",
      " 36  RM                        16122 non-null  float64\n",
      " 37  LWB                       16122 non-null  float64\n",
      " 38  LDM                       16122 non-null  float64\n",
      " 39  CDM                       16122 non-null  float64\n",
      " 40  RDM                       16122 non-null  float64\n",
      " 41  RWB                       16122 non-null  float64\n",
      " 42  LB                        16122 non-null  float64\n",
      " 43  LCB                       16122 non-null  float64\n",
      " 44  CB                        16122 non-null  float64\n",
      " 45  RCB                       16122 non-null  float64\n",
      " 46  RB                        16122 non-null  float64\n",
      " 47  Crossing                  18159 non-null  float64\n",
      " 48  Finishing                 18159 non-null  float64\n",
      " 49  HeadingAccuracy           18159 non-null  float64\n",
      " 50  ShortPassing              18159 non-null  float64\n",
      " 51  Volleys                   18159 non-null  float64\n",
      " 52  Dribbling                 18159 non-null  float64\n",
      " 53  Curve                     18159 non-null  float64\n",
      " 54  FKAccuracy                18159 non-null  float64\n",
      " 55  LongPassing               18159 non-null  float64\n",
      " 56  BallControl               18159 non-null  float64\n",
      " 57  Acceleration              18159 non-null  float64\n",
      " 58  SprintSpeed               18159 non-null  float64\n",
      " 59  Agility                   18159 non-null  float64\n",
      " 60  Reactions                 18159 non-null  float64\n",
      " 61  Balance                   18159 non-null  float64\n",
      " 62  ShotPower                 18159 non-null  float64\n",
      " 63  Jumping                   18159 non-null  float64\n",
      " 64  Stamina                   18159 non-null  float64\n",
      " 65  Strength                  18159 non-null  float64\n",
      " 66  LongShots                 18159 non-null  float64\n",
      " 67  Aggression                18159 non-null  float64\n",
      " 68  Interceptions             18159 non-null  float64\n",
      " 69  Positioning               18159 non-null  float64\n",
      " 70  Vision                    18159 non-null  float64\n",
      " 71  Penalties                 18159 non-null  float64\n",
      " 72  Composure                 18159 non-null  float64\n",
      " 73  Marking                   18159 non-null  float64\n",
      " 74  StandingTackle            18159 non-null  float64\n",
      " 75  SlidingTackle             18159 non-null  float64\n",
      " 76  GKDiving                  18159 non-null  float64\n",
      " 77  GKHandling                18159 non-null  float64\n",
      " 78  GKKicking                 18159 non-null  float64\n",
      " 79  GKPositioning             18159 non-null  float64\n",
      " 80  GKReflexes                18159 non-null  float64\n",
      " 81  Release Clause            18159 non-null  int64  \n",
      " 82  Position simplified       18159 non-null  object \n",
      "dtypes: float64(67), int64(7), object(9)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./FIFA2.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        3\n",
       "4        1\n",
       "        ..\n",
       "18154    1\n",
       "18155    0\n",
       "18156    0\n",
       "18157    0\n",
       "18158    1\n",
       "Name: Position simplified, Length: 18159, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_position = {'FW':0, 'MD':1, 'DF':2, 'GK':3}\n",
    "col = ['Position simplified']\n",
    "data[col] = data[col].applymap(map_position.get)\n",
    "data['Position simplified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, 'Crossing':'GKReflexes']\n",
    "XX = X.drop('Strength', axis=1)\n",
    "y = data.loc[:, 'Position simplified']\n",
    "xy = pd.concat([X, y], axis=1)\n",
    "xxy = pd.concat([XX, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "def get_model_train_eval(model, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    model.fit(X_train, y_train)\n",
    "    print('{} Test Accuracy: {}%'.format(model, round(model.score(X_test, y_test)*100, 2)))\n",
    "\n",
    "\n",
    "    pred_model = model.predict(X_test)\n",
    "    print('{} report:{}\\n'.format(model.__class__.__name__, classification_report(y_test, pred_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 270 candidates, totalling 810 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 76.1min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 171.5min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 314.0min\n",
      "[Parallel(n_jobs=8)]: Done 810 out of 810 | elapsed: 327.3min finished\n",
      "[09:16:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('xgbclassifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weig...\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=8,\n",
       "             param_grid=[{'xgbclassifier__gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                          'xgbclassifier__learning_rate': [0.01, 0.05, 0.1,\n",
       "                                                           0.15, 0.2],\n",
       "                          'xgbclassifier__max_depth': [3, 6, 9],\n",
       "                          'xgbclassifier__min_child_weight': [1, 3, 5],\n",
       "                          'xgbclassifier__n_estimators': [1000],\n",
       "                          'xgbclassifier__objective': ['multi:softmax']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), XGBClassifier())\n",
    "\n",
    "param_grid = [\n",
    "    {'xgbclassifier__n_estimators': [1000],\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2], \n",
    "    'xgbclassifier__max_depth': [3, 6, 9],\n",
    "    'xgbclassifier__min_child_weight': [1, 3, 5],\n",
    "    'xgbclassifier__objective': ['multi:softmax'],\n",
    "    'xgbclassifier__gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5] }\n",
    "]\n",
    "\n",
    "grid_model_xgb = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    cv=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0.3, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=9,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=1000,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 270 candidates, totalling 810 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 83.9min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 199.7min\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(grid_model_xgb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  2.7min finished\n",
      "[17:25:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('xgbclassifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weig...\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=8,\n",
       "             param_grid=[{'xgbclassifier__gamma': [0.3],\n",
       "                          'xgbclassifier__learning_rate': [0.05],\n",
       "                          'xgbclassifier__max_depth': [9],\n",
       "                          'xgbclassifier__min_child_weight': [1],\n",
       "                          'xgbclassifier__n_estimators': [1000],\n",
       "                          'xgbclassifier__objective': ['multi:softmax']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), XGBClassifier())\n",
    "\n",
    "param_grid = [\n",
    "    {'xgbclassifier__n_estimators': [1000],\n",
    "    'xgbclassifier__learning_rate': [0.05], \n",
    "    'xgbclassifier__max_depth': [9],\n",
    "    'xgbclassifier__min_child_weight': [1],\n",
    "    'xgbclassifier__objective': ['multi:softmax'],\n",
    "    'xgbclassifier__gamma': [0.3] }\n",
    "]\n",
    "\n",
    "grid_model_xgb = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    cv=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  2.6min finished\n",
      "[17:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                       ('xgbclassifier',\n",
      "                                        XGBClassifier(base_score=None,\n",
      "                                                      booster=None,\n",
      "                                                      colsample_bylevel=None,\n",
      "                                                      colsample_bynode=None,\n",
      "                                                      colsample_bytree=None,\n",
      "                                                      gamma=None, gpu_id=None,\n",
      "                                                      importance_type='gain',\n",
      "                                                      interaction_constraints=None,\n",
      "                                                      learning_rate=None,\n",
      "                                                      max_delta_step=None,\n",
      "                                                      max_depth=None,\n",
      "                                                      min_child_weig...\n",
      "                                                      scale_pos_weight=None,\n",
      "                                                      subsample=None,\n",
      "                                                      tree_method=None,\n",
      "                                                      validate_parameters=None,\n",
      "                                                      verbosity=None))]),\n",
      "             n_jobs=8,\n",
      "             param_grid=[{'xgbclassifier__gamma': [0.3],\n",
      "                          'xgbclassifier__learning_rate': [0.05],\n",
      "                          'xgbclassifier__max_depth': [9],\n",
      "                          'xgbclassifier__min_child_weight': [1],\n",
      "                          'xgbclassifier__n_estimators': [1000],\n",
      "                          'xgbclassifier__objective': ['multi:softmax']}],\n",
      "             verbose=True) Test Accuracy: 88.3%\n",
      "GridSearchCV report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       684\n",
      "           1       0.84      0.87      0.85      1368\n",
      "           2       0.92      0.93      0.93      1173\n",
      "           3       1.00      0.99      0.99       407\n",
      "\n",
      "    accuracy                           0.88      3632\n",
      "   macro avg       0.90      0.89      0.89      3632\n",
      "weighted avg       0.88      0.88      0.88      3632\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(grid_model_xgb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  2.7min finished\n",
      "[17:38:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('xgbclassifier',\n",
       "                                        XGBClassifier(base_score=0.5,\n",
       "                                                      booster='gbtree',\n",
       "                                                      colsample_bylevel=1,\n",
       "                                                      colsample_bynode=1,\n",
       "                                                      colsample_bytree=1,\n",
       "                                                      gamma=0.3, gpu_id=-1,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints='',\n",
       "                                                      learning_rate=0.05,\n",
       "                                                      max_delta_step=0,\n",
       "                                                      max_depth=9,\n",
       "                                                      min_child_weight=1,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints='()',\n",
       "                                                      n_estimators=1000,\n",
       "                                                      n_jobs=8,\n",
       "                                                      num_parallel_tree=1,\n",
       "                                                      objective='multi:softprob',\n",
       "                                                      random_state=0,\n",
       "                                                      reg_alpha=0, reg_lambda=1,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=1,\n",
       "                                                      tree_method='exact',\n",
       "                                                      validate_parameters=1,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=8, param_grid={}, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pipe = make_pipeline(StandardScaler(), XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                               colsample_bylevel=1, colsample_bynode=1,\n",
    "                               colsample_bytree=1, gamma=0.3, gpu_id=-1,\n",
    "                               importance_type='gain',\n",
    "                               interaction_constraints='', learning_rate=0.05,\n",
    "                               max_delta_step=0, max_depth=9,\n",
    "                               min_child_weight=1, missing=np.nan,\n",
    "                               monotone_constraints='()', n_estimators=1000,\n",
    "                               n_jobs=8, num_parallel_tree=1,\n",
    "                               objective='multi:softprob', random_state=0,\n",
    "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
    "                               subsample=1, tree_method='exact',\n",
    "                               validate_parameters=1, verbosity=None))\n",
    "\n",
    "param_grid = {}\n",
    "\n",
    "grid_model_xgb2 = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    cv=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_model_xgb2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  2.4min finished\n",
      "[17:41:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                       ('xgbclassifier',\n",
      "                                        XGBClassifier(base_score=0.5,\n",
      "                                                      booster='gbtree',\n",
      "                                                      colsample_bylevel=1,\n",
      "                                                      colsample_bynode=1,\n",
      "                                                      colsample_bytree=1,\n",
      "                                                      gamma=0.3, gpu_id=-1,\n",
      "                                                      importance_type='gain',\n",
      "                                                      interaction_constraints='',\n",
      "                                                      learning_rate=0.05,\n",
      "                                                      max_delta_step=0,\n",
      "                                                      max_depth=9,\n",
      "                                                      min_child_weight=1,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints='()',\n",
      "                                                      n_estimators=1000,\n",
      "                                                      n_jobs=8,\n",
      "                                                      num_parallel_tree=1,\n",
      "                                                      objective='multi:softprob',\n",
      "                                                      random_state=0,\n",
      "                                                      reg_alpha=0, reg_lambda=1,\n",
      "                                                      scale_pos_weight=None,\n",
      "                                                      subsample=1,\n",
      "                                                      tree_method='exact',\n",
      "                                                      validate_parameters=1,\n",
      "                                                      verbosity=None))]),\n",
      "             n_jobs=8, param_grid={}, verbose=True) Test Accuracy: 88.3%\n",
      "GridSearchCV report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       684\n",
      "           1       0.84      0.87      0.85      1368\n",
      "           2       0.92      0.93      0.93      1173\n",
      "           3       1.00      0.99      0.99       407\n",
      "\n",
      "    accuracy                           0.88      3632\n",
      "   macro avg       0.90      0.89      0.89      3632\n",
      "weighted avg       0.88      0.88      0.88      3632\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(grid_model_xgb2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=8)]: Done 144 out of 144 | elapsed: 93.9min finished\n",
      "[19:20:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('xgbclassifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weig...\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=8,\n",
       "             param_grid=[{'xgbclassifier__gamma': [0.1, 0.3, 0.5],\n",
       "                          'xgbclassifier__learning_rate': [0.01, 0.05, 0.1,\n",
       "                                                           0.15],\n",
       "                          'xgbclassifier__max_depth': [6, 9],\n",
       "                          'xgbclassifier__min_child_weight': [1, 3],\n",
       "                          'xgbclassifier__n_estimators': [1000],\n",
       "                          'xgbclassifier__objective': ['multi:softmax']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), XGBClassifier())\n",
    "\n",
    "param_grid = [\n",
    "    {'xgbclassifier__n_estimators': [1000],\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.05, 0.1, 0.15], \n",
    "    'xgbclassifier__max_depth': [6, 9],\n",
    "    'xgbclassifier__min_child_weight': [1, 3],\n",
    "    'xgbclassifier__objective': ['multi:softmax'],\n",
    "    'xgbclassifier__gamma': [0.1, 0.3, 0.5] }\n",
    "]\n",
    "\n",
    "grid_model_xgb2 = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    cv=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_model_xgb2.fit(XX_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.01,\n",
       "                               max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=3, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=1000,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model_xgb2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(grid_model_xgb2, XX_train, XX_test, yy_train, yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  1.9min finished\n",
      "[19:45:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('xgbclassifier',\n",
       "                                        XGBClassifier(base_score=0.5,\n",
       "                                                      booster='gbtree',\n",
       "                                                      colsample_bylevel=1,\n",
       "                                                      colsample_bynode=1,\n",
       "                                                      colsample_bytree=1,\n",
       "                                                      gamma=0.1, gpu_id=-1,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints='',\n",
       "                                                      learning_rate=0.01,\n",
       "                                                      max_delta_step=0,\n",
       "                                                      max_depth=6,\n",
       "                                                      min_child_weight=3,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints='()',\n",
       "                                                      n_estimators=1000,\n",
       "                                                      n_jobs=8,\n",
       "                                                      num_parallel_tree=1,\n",
       "                                                      objective='multi:softprob',\n",
       "                                                      random_state=0,\n",
       "                                                      reg_alpha=0, reg_lambda=1,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=1,\n",
       "                                                      tree_method='exact',\n",
       "                                                      validate_parameters=1,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=8, param_grid={}, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "pipe = make_pipeline(StandardScaler(), XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                               colsample_bylevel=1, colsample_bynode=1,\n",
    "                               colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
    "                               importance_type='gain',\n",
    "                               interaction_constraints='', learning_rate=0.01,\n",
    "                               max_delta_step=0, max_depth=6,\n",
    "                               min_child_weight=3, missing=np.nan,\n",
    "                               monotone_constraints='()', n_estimators=1000,\n",
    "                               n_jobs=8, num_parallel_tree=1,\n",
    "                               objective='multi:softprob', random_state=0,\n",
    "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
    "                               subsample=1, tree_method='exact',\n",
    "                               validate_parameters=1, verbosity=None))\n",
    "\n",
    "param_grid = {}\n",
    "\n",
    "grid_model_xgb3 = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    cv=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_model_xgb3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  2.1min finished\n",
      "[19:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                       ('xgbclassifier',\n",
      "                                        XGBClassifier(base_score=0.5,\n",
      "                                                      booster='gbtree',\n",
      "                                                      colsample_bylevel=1,\n",
      "                                                      colsample_bynode=1,\n",
      "                                                      colsample_bytree=1,\n",
      "                                                      gamma=0.1, gpu_id=-1,\n",
      "                                                      importance_type='gain',\n",
      "                                                      interaction_constraints='',\n",
      "                                                      learning_rate=0.01,\n",
      "                                                      max_delta_step=0,\n",
      "                                                      max_depth=6,\n",
      "                                                      min_child_weight=3,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints='()',\n",
      "                                                      n_estimators=1000,\n",
      "                                                      n_jobs=8,\n",
      "                                                      num_parallel_tree=1,\n",
      "                                                      objective='multi:softprob',\n",
      "                                                      random_state=0,\n",
      "                                                      reg_alpha=0, reg_lambda=1,\n",
      "                                                      scale_pos_weight=None,\n",
      "                                                      subsample=1,\n",
      "                                                      tree_method='exact',\n",
      "                                                      validate_parameters=1,\n",
      "                                                      verbosity=None))]),\n",
      "             n_jobs=8, param_grid={}, verbose=True) Test Accuracy: 88.24%\n",
      "GridSearchCV report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       684\n",
      "           1       0.83      0.87      0.85      1368\n",
      "           2       0.92      0.93      0.93      1173\n",
      "           3       1.00      0.99      0.99       407\n",
      "\n",
      "    accuracy                           0.88      3632\n",
      "   macro avg       0.90      0.89      0.89      3632\n",
      "weighted avg       0.88      0.88      0.88      3632\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(grid_model_xgb3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
